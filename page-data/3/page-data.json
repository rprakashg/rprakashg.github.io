{"componentChunkName":"component---src-templates-post-list-js","path":"/3/","result":{"data":{"site":{"siteMetadata":{"title":"rprakashg.github.io","author":"RAM GOPINATHAN"}},"allMarkdownRemark":{"totalCount":36,"edges":[{"node":{"excerpt":"In my current role I'm always having a ton of conversations with customers regarding Kubernetes fleet management and managing clusters at scale in hybrid cloud environments. While we have a lot of pre…","html":"<p>In my current role I'm always having a ton of conversations with customers regarding Kubernetes fleet management and managing clusters at scale in hybrid cloud environments. While we have a lot of pre-built demos at <a href=\"https://demo.redhat.com\">demo.redhat.com</a> I usually end up my building a lot of it myself because I can really make something thats very specific to a particular customer I'm working and its also easier to explain and walkthrough something you built v/s what someone else built.</p>\n<p>The way I use to install and configure before was by logging into OpenShift console and following installation instructions in our product documentation for Red Hat Advanced Cluster Management for Kubernetes. This started to become so time consuming and inefficient over time and I decided to use Ansible to automate installing and configuring ACM. Ansible is great at configuring infrastructure once its provisioned.</p>\n<p>Ansible community has created a collection for kubernetes, if you are not familiar with it please check out this <a href=\"https://docs.ansible.com/ansible/latest/collections/kubernetes/core/index.html#plugins-in-kubernetes-core\">documentation</a>. I'm using the k8s module from this collection which allows me to manage k8s objects on a kubernetes cluster.</p>\n<p>You can find everything I'm covering in this post here in this <a href=\"https://github.com/rprakashg-redhat/rhacm-demos/tree/main/install\">directory</a> of Github <a href=\"https://github.com/rprakashg-redhat/rhacm-demos\">repo</a>. You are welcome to use it at your own risk.</p>\n<p>To install and configure ACM I first login to the OpenShift cluster where I want to install ACM and then run this command <em><code class=\"language-text\">ansible-playbook install/install-configure-acm-playbook.yaml</code></em>. The Ansible playbook is pretty self explanatory so I wont go into too much details but at a high level what happens is as follows</p>\n<ul>\n<li>Load static variable values defined in yaml file.</li>\n<li>Extract pull secret that was used when cluster was installed.</li>\n<li>Write the data into a dynamic vars yaml file (I use .gitignore to exclude everything in dynamic vars directory so it doesn't get accidently checked in to Github).</li>\n<li>Load the dynamic variable values.</li>\n<li>Create open cluster management namespace.</li>\n<li>Create the operator group.</li>\n<li>Install ACM operator and wait for operator to be ready.</li>\n<li>With the pull secret that was extracted and saved into dynamic variable values file create a pull secret in open cluster management namespace for multi cluster hub.</li>\n<li>Create an instance of multi cluster hub and wait for the hub to be ready</li>\n<li>Install OpenShift GitOps Operator (ArgoCD) and wait for operator to be ready</li>\n</ul>\n<p><a href=\"https://asciinema.org/a/AQBvzRfPARRyRglJ8smO1FNZk\"><img src=\"https://asciinema.org/a/AQBvzRfPARRyRglJ8smO1FNZk.svg\" alt=\"asciicast\"></a></p>\n<p>Now we can switch back to Openshift console and refresh the console to check the status of ACM install and configuration. From the screen capture below you can see we now have RHACM all installed and configured</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4ef5ca703521ae592cbc761e2f79bd62/45689/acm-install-result.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABeUlEQVR42pWOT0sbQRjG91sUUWO0apSqLaH3VqmBKkhprh489I8UqYdCj4mhggdB889GsypV4sFPYQ+aQr146rGXfoBsqruZ3ZnNr7OznnrSgR/P874P88xYpycnnDYaHB5+o1YpU93e4mC3xkHtK/Vqxfgju87xvk1tp0q5WKRSKlEuFWNu54gdfd9K9PbT35fgQU8fmex7Flc2+LhWZ7Vgs5Lb1d5mNb/H53WbpU+bLLzLkf1Q4LXm1XKB+bdrvHyTZ07rwvIXrJnMHM+mZ3k+/YLzn1eEQNANNSA10azlzseaevKUycdpRlKPaDabZum5N7rV49cfh8vfDr4QCM8llD5KE8ogRsXa1aoCnQUCa2IqzdDwGInkMOcXP+JCz0MqybUrcK49fD/AdTv8vfHoCJ9OR+idj4geusXXhSIqTI1PmsKBwREumnGhlJIwDOkalPERUoUopUz+P0EQmE9YyaFRBh+miPTs7LsJWq0W7Xb7XjiOY/gHmoPC3nkd4U0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rhacm\"\n        title=\"\"\n        src=\"/static/4ef5ca703521ae592cbc761e2f79bd62/5a190/acm-install-result.png\"\n        srcset=\"/static/4ef5ca703521ae592cbc761e2f79bd62/772e8/acm-install-result.png 200w,\n/static/4ef5ca703521ae592cbc761e2f79bd62/e17e5/acm-install-result.png 400w,\n/static/4ef5ca703521ae592cbc761e2f79bd62/5a190/acm-install-result.png 800w,\n/static/4ef5ca703521ae592cbc761e2f79bd62/c1b63/acm-install-result.png 1200w,\n/static/4ef5ca703521ae592cbc761e2f79bd62/29007/acm-install-result.png 1600w,\n/static/4ef5ca703521ae592cbc761e2f79bd62/45689/acm-install-result.png 2249w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>If you have any questions please feel free to reach out.</p>\n<p>Hope that was helpful</p>\n<p>Thanks,\nRam</p>","id":"6fdcd152-8edc-549a-af62-e6dba93f28aa","frontmatter":{"title":"Using Ansible for installing and configuring Red Hat Advanced Cluster Management for Kubernetes (RHACM)","date":"March 22, 2024","tags":["OpenShift","Platform","Kubernetes","Management"],"author":"Ram Gopinathan"},"fields":{"slug":"/using-ansible-to-install-configure-rhacm/"}}},{"node":{"excerpt":"As many of you may already know Red Hat Developer hub which is based on backstage project created by Spotify hit GA. If you are not familiar with RedHat Developer hub or backstage check out this…","html":"<p>As many of you may already know Red Hat Developer hub which is based on backstage project created by Spotify hit GA. If you are not familiar with RedHat Developer hub or backstage check out this <a href=\"https://developers.redhat.com/rhdh\">article</a>. You can deploy and run developer hub on all x-K8s (AKS, EKS, GKE). In this post I will cover how to install and configure RedHat developer hub on Amazon Elastic Kubernetes Service (EKS). If you are using AKS or GKE I would think these steps would work just fine although I haven't tested in AKS or GKE. Everything I'm covering in this post can be found in this Github <a href=\"https://github.com/rprakashg-redhat/rhdh-on-eks\">repo</a>.</p>\n<p>Lets get right into it.</p>\n<p>As in many previous posts where I used EKS I'm going to use terraform to provision EKS cluster. You can find the terraform scripts <a href=\"https://github.com/rprakashg-redhat/rhdh-on-eks/tree/main/deploy/infra\">here</a>.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">terraform init\nterraform plan\nterraform apply --var \"name=toolscluster\"</code></pre></div>\n<p>Once the cluster is provisioned we need to install an Ingress controller. There are variety of options out there but for the purposes of this post I decided to use HAProxy. HAProxy also provides an EKS addon that makes it super easy to install on to cluster but I'm going to use helm to install HAProxy controller on the cluster.</p>\n<p>You can download the kubeconfig file to authenticate with the cluster by running command below.</p>\n<p>note: <em>Be sure to make sure region value matches to one you specified when cluster was created.</em></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">aws eks update-kubeconfig --region us-west-2 --name \"toolscluster\"</code></pre></div>\n<p>First we are going to add the HAProxy helm chart repo by running command below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm repo add haproxytech https://haproxytech.github.io/helm-charts</code></pre></div>\n<p>Update helm charts by running <code class=\"language-text\">helm repo update</code> and install the HAProxy ingress controller by running command below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm install haproxy-kubernetes-ingress haproxytech/kubernetes-ingress \\\n  --create-namespace \\\n  --namespace haproxy-controller \\\n  --set controller.service.type=LoadBalancer</code></pre></div>\n<p>Check if the ALB is provisioned successfully on AWS by running <em><code class=\"language-text\">kubectl describe service haproxy-ingress -n haproxy-controller</code></em>. You should see full DNS name of your ALB provisioned in Amazon for public IP. If it shows pending that means some issue which you should see in the status section.</p>\n<p>Next thing we are going to do is to update the route 53 hosted zone to create an A record so we can have a friendly URL like so <em><code class=\"language-text\">devhub.sandbox2841.opentlc.com</code></em>. Basically this is going to act as an alias for routing traffic to the ALB provisioned by HAProxy Ingress controller. See screenshopt below</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/006e0d3131e87b186c82c19ea6463e89/18c33/r53updates.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABGklEQVR42pWS+06DMBjFef/H8gl08ZKYsDllUjagtPTG9XjaTeMfLmrJL18bei4JZDebHHePz9g8POF2c498t4c4HlFWglR/5r0UeCsOyE6NRFWVUErBBw8XAsIw/BtPnXMO2WtZ4SAqnJoWTdui5tR9DxXR+sznmXQ8/wgLxZmVNKtbeRH3NDPQ1id8uCR7n4j7gW0S45jmyDlOEyzbpYbGGEjZwViLQIPvDMMITyPLd1FgjIWzZ2EiBnEqpXk/JLJpmilwKem3ta7rV6OVz7IsyXC7e0mFolcWmHLkV22bBss8R9VVVhrE+54mcc00j/uiKJJ+ZlAmhUCx2+JAOhq7roOV8irqxHBq4j1d15D8ZYo8h9jv4bXCB3NJZmPOVaChAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"r53update\"\n        title=\"\"\n        src=\"/static/006e0d3131e87b186c82c19ea6463e89/5a190/r53updates.png\"\n        srcset=\"/static/006e0d3131e87b186c82c19ea6463e89/772e8/r53updates.png 200w,\n/static/006e0d3131e87b186c82c19ea6463e89/e17e5/r53updates.png 400w,\n/static/006e0d3131e87b186c82c19ea6463e89/5a190/r53updates.png 800w,\n/static/006e0d3131e87b186c82c19ea6463e89/c1b63/r53updates.png 1200w,\n/static/006e0d3131e87b186c82c19ea6463e89/29007/r53updates.png 1600w,\n/static/006e0d3131e87b186c82c19ea6463e89/18c33/r53updates.png 1775w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Create a namespace <code class=\"language-text\">tools</code> on the cluster where we will install developer hub components by running <em><code class=\"language-text\">kubectl create namespace tools</code></em></p>\n<p>Next thing we are going to do is download redhat pull secret file from <em>cloud.redhat.com</em> and save it locally as pull-secret.txt file then create a kubernetes secret as shown below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl create secret generic rhdh-pull-secret \\\n  -n tools \\\n  --from-file=.dockerconfigjson=pull-secret.txt \\\n  --type=kubernetes.io/dockerconfigjson</code></pre></div>\n<p>Path the default service account to be able to pull images from redhat registries using the kubernetes secret we created earlier by running command below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl patch sa default -n tools -p '{\"imagePullSecrets\": [{\"name\": \"rhdh-pull-secret\"}]}'</code></pre></div>\n<p>Next thing we are going to do is create a kubernetes secret to store all sensitive configurations we want to use in the app config file for backstage. See below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl create secret generic rhdh-secrets \\\n  -n tools \\\n  --from-literal=AUTH_OKTA_CLIENT_ID=${AUTH_OKTA_CLIENT_ID} \\\n--from-literal=AUTH_OKTA_CLIENT_SECRET=${AUTH_OKTA_CLIENT_SECRET} \\\n--from-literal=AUTH_OKTA_DOMAIN=${AUTH_OKTA_DOMAIN} \\\n--from-literal=AUTH_OKTA_ADDITIONAL_SCOPES=${AUTH_OKTA_ADDITIONAL_SCOPES} \\\n--from-literal=GITLAB_TOKEN=${GITLAB_TOKEN} \\\n--from-literal=GITLAB_APP_APP_ID=${GITLAB_APP_APP_ID} \\\n--from-literal=GITLAB_APP_CLIENT_ID=${GITLAB_APP_CLIENT_ID} \\\n--from-literal=GITLAB_APP_CLIENT_SECRET=${GITLAB_APP_CLIENT_SECRET} \\\n--from-literal=GITHUB_APP_APP_ID=${GITHUB_APP_APP_ID} \\\n--from-literal=GITHUB_APP_CLIENT_ID=${GITHUB_APP_CLIENT_ID} \\\n--from-literal=GITHUB_APP_CLIENT_SECRET=${GITHUB_APP_CLIENT_SECRET} \\\n--from-literal=GITHUB_ORG=${GITHUB_ORG} \\\n--from-literal=GITHUB_APP_WEBHOOK_URL=${GITHUB_APP_WEBHOOK_URL} \\\n--from-literal=GITHUB_APP_WEBHOOK_SECRET=${GITHUB_APP_WEBHOOK_SECRET} \\\n--from-literal=GITHUB_TOKEN=${GITHUB_TOKEN} \\\n--from-literal=BACKSTAGE_AWS_ACCOUNT_ID=${BACKSTAGE_AWS_ACCOUNT_ID} \\\n--from-literal=AWS_ACCESS_KEY_ID=${BACKSTAGE_AWS_ACCESS_KEY_ID} \\\n--from-literal=AWS_SECRET_ACCESS_KEY=${BACKSTAGE_AWS_SECRET_ACCESS_KEY} \\\n--from-literal=TECHDOCS_AWSS3_BUCKET_NAME=${TECHDOCS_AWSS3_BUCKET_NAME} \\\n--from-literal=TECHDOCS_AWSS3_BUCKET_URL=${TECHDOCS_AWSS3_BUCKET_URL} \\\n--from-literal=AWS_REGION=${AWS_REGION} \\\n--from-literal=EKS_CLUSTER_URL=${EKS_CLUSTER_URL} \\\n--from-literal=EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME} \\\n--from-literal=BACKSTAGE_ROLE_ARN_TO_ASSUME=${BACKSTAGE_ROLE_ARN_TO_ASSUME} \\\n--from-literal=AWS_EXTERNAL_ID=${AWS_EXTERNAL_ID} \\\n--from-literal=EKS_SA_TOKEN=${EKS_SA_TOKEN} \\\n--from-literal=ARGOCD_USER_ID=${ARGOCD_USER_ID} \\\n--from-literal=ARGOCD_USER_PWD=${ARGOCD_USER_PWD}</code></pre></div>\n<p>I was testing OKTA, GITHUB, GITLAB mine looks pretty large. Approach I took was to keep a local env file that contains all the values specific to my environment\nand I would run command <em><code class=\"language-text\">export $(cat local.env | xargs)</code></em>  before creating the secret.</p>\n<p>Originally for Auth I used OKTA and eventually landed on using GitHub. Steps for creating app in github is pretty well documented so I'm not going to cover that. Once you create the app in github you will endup having to create a private key as well. Download the private key in to your local machine and create another kubernetes secret to store the private key for your app as you will need to specify that in the app config for backstage</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl create secret generic -n tools gh-app-key \\\n--from-file=GITHUB_APP_PRIVATE_KEY=\"/Users/rgopinat/keys/demo-rhdh.2024-02-26.private-key.pem\"</code></pre></div>\n<p>For Kubernetes plugin I downloaded the EKS CA Certificate from aws console and saved locally to create another secret to store that EKC CA data as shown below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl create secret generic -n tools eks-ca-data \\\n--from-file=EKS_CA_DATA=eks-ca.txt</code></pre></div>\n<p>Next I do have to tell backstage about all these secrets I've created so backstage can load them as environment variables and we can do that by updating a section in values file as shown below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"> extraEnvVarsSecrets:\n    - rhdh-secrets\n    - gh-app-key\n    - eks-ca-data</code></pre></div>\n<p>Next thing we are going to do is to go ahead and create the app config configmap. You can see a copy of mine <a href=\"https://github.com/rprakashg-redhat/rhdh-on-eks/blob/main/deploy/rhdh/developer-hub-appconfig.yaml\">here</a></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">kubectl apply -f deploy/rhdh/developer-hub-appconfig.yaml</code></pre></div>\n<p>It is worth talking a little bit about this snippet of yaml below in the app config. Basically this is going to tell backstage to automatically ingest entities from github and the two static locations you see are one for golden path templates and the other one is for ingesting all APIs from repo where I'm storing all API specifications</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">catalog:\n    import:\n    entityFileName: catalog-info.yaml\n    rules:\n    - allow: [Component, System, API, Resource, Location, Domain, Template]\n    locations:\n    - type: url\n        target: https://github.com/rprakashg-redhat/rhdh-templates/blob/main/all-templates.yaml\n    - type: url\n        target: https://github.com/rprakashg-redhat/apis/blob/main/all-apis.yaml</code></pre></div>\n<p>At this point we are ready to install redhat developer hub. We provide a Helm chart to do just that. We will add the helm chart repo with this command <em><code class=\"language-text\">helm repo add openshift-helm-charts https://charts.openshift.io/</code></em>. Next we need to download the values yaml so we can review and customize them to fit to this EKS installation.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm show values openshift-helm-charts/redhat-developer-hub > values.yaml</code></pre></div>\n<p>Customize the values yaml. You can see the version I used for my installation <a href=\"https://github.com/rprakashg-redhat/rhdh-on-eks/blob/main/deploy/rhdh/values.yaml\">here</a>.\nFew other customizations to values file that are worth calling out are below</p>\n<ol>\n<li>Specified the custom hostname <code class=\"language-text\">devhub.sandbox2841.opentlc.com</code> under section global of values yaml</li>\n<li>Since I was using HAProxy ingress under upstream section I had to enable ingress and specify className as shown in the snippet below</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ingress:\n    enabled: true\n    host: \"{{ .Values.global.host }}\"\n    className: haproxy</code></pre></div>\n<ol start=\"3\">\n<li>Tell developer hub about the app config by updating the extraAppConfig section under upstream->backstage section in values file as shown in snippet below</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">extraAppConfig:\n- configMapRef: \"developer-hub-appconfig\"\n  filename: \"developer-hub-appconfig.yaml\"</code></pre></div>\n<ol start=\"4\">\n<li>Update podSecurityContext section under upstream->backstage and include below config</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">podSecurityContext:\n    runAsUser: 1001\n    runAsGroup: 1001\n    fsGroup: 1001</code></pre></div>\n<ol start=\"5\">\n<li>Update podSecurityContext section under upstream->postgresql->primary section in values file as shown in snippet below</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">podSecurityContext:\n    enabled: true\n    fsGroup: 26\n    runAsUser: 26</code></pre></div>\n<p>and set volume permissions to enabled as shown in snippet below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">volumePermissions:\n    enabled: true</code></pre></div>\n<ol start=\"6\">\n<li>Lastly I had to set route enabled to false since I'm not running developer hub on Openshift.</li>\n</ol>\n<p>At this point we can go ahead and install redhat developer hub by running command <em><code class=\"language-text\">helm upgrade --namespace tools -i developer-hub -f values.yaml openshift-helm-charts/redhat-developer-hub</code></em></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm upgrade --namespace tools -i developer-hub -f values.yaml openshift-helm-charts/redhat-developer-hub</code></pre></div>\n<p>Browse to <em><code class=\"language-text\">https://devhub.sandbox2841.opentlc.com</code></em> from a browser and login and you will be in home page of developer hub as shown in screen capture below</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/28b17bc865fbf5cf1eddb74c31dd8d3f/c2d13/devhubhome.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABFUlEQVR42oWQyU7DMBCG/UpIXErpQuGZWKQ0cKRcCqqKql7CI3FFLEpFgKaBRNmc2Fl+xgYkhNJi6dN4xv5/z5i1trZxa57BPr/AnTHEvXmKx6GJh8MjPB2fwDYMLCh/GY3wNh7DvbyCN5ngfT6Hb1kIrBuEiusp4tkMrNMf4HXpQpYlZFVBUBQUZV03kgqBKMv0XUVWSEhAo3SsPziA4ziQUqCmQk0iHRuo6LEoDOEHAXiaIuMcJdWq77OiKMDanR4W9rNOyAqblhLmea7hZKbIqNufmoLt7HaxWnlaoLvbwG/DdbBWuwvPXSJOOdJc/tuhoD9cZ6bOWG9vH77/oUcW8stQ/Yuk/V+UIEkSPWqTWRTH+ATO9QPErE/ovAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"devhubhome\"\n        title=\"\"\n        src=\"/static/28b17bc865fbf5cf1eddb74c31dd8d3f/5a190/devhubhome.png\"\n        srcset=\"/static/28b17bc865fbf5cf1eddb74c31dd8d3f/772e8/devhubhome.png 200w,\n/static/28b17bc865fbf5cf1eddb74c31dd8d3f/e17e5/devhubhome.png 400w,\n/static/28b17bc865fbf5cf1eddb74c31dd8d3f/5a190/devhubhome.png 800w,\n/static/28b17bc865fbf5cf1eddb74c31dd8d3f/c1b63/devhubhome.png 1200w,\n/static/28b17bc865fbf5cf1eddb74c31dd8d3f/29007/devhubhome.png 1600w,\n/static/28b17bc865fbf5cf1eddb74c31dd8d3f/c2d13/devhubhome.png 2560w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Navigating to APIs you can see that petstore api was ingested into catalog automatically from the repo. Currently repo has only one API spec but as we add more API specs they would be automatically ingested into the catalog which is super cool.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b38495c951fb65d0bdb74d3f88c140f0/c2d13/apis.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdklEQVR42p2Qy07bUBRF/VNIlQptESp/AA0tj34AUyJAoAqplfgixp12yis8bNlJnIcdnKTx9bUdJ1mca2AAUiYMts5jn7vvPsfy601adoP7Kw+71sC5kfzCwZXYtNslGvdtfLtDyw3w3ZCWF+LXHwQR3WZEz39Cx+tirSx84F/lO5ffKpxXNqjt/OT6xya1tXXupLY3t3C2d6jv7uLv7dGuVukeHBCenNA/PSX4/Qf38BdBdR91fIS1uPSZjuuSDf+jej1G3QAd9ckGQ9K+iQPhhuRKkcfxE0Yx2WjETCfUxdXZ3wtubpulhrW8skonCCimU3SWEUkzLwqmQD6ZlLGYzlBpxmQ2o5BeonU5W86Mc7JUk0odJ4k4/LSM53kocTAUJ0qamZBpmr6CEXnJtRF8rk1UiSaRdyYXwS84jsNA1uvJyvpZ8L2wPsoNwzBkPB6Xv5hfDZHn+VzMEzOc3PArURRRyN2MZUOUa8gJ5uFl7q1YrBSPxtpBSg4C1TgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"apis\"\n        title=\"\"\n        src=\"/static/b38495c951fb65d0bdb74d3f88c140f0/5a190/apis.png\"\n        srcset=\"/static/b38495c951fb65d0bdb74d3f88c140f0/772e8/apis.png 200w,\n/static/b38495c951fb65d0bdb74d3f88c140f0/e17e5/apis.png 400w,\n/static/b38495c951fb65d0bdb74d3f88c140f0/5a190/apis.png 800w,\n/static/b38495c951fb65d0bdb74d3f88c140f0/c1b63/apis.png 1200w,\n/static/b38495c951fb65d0bdb74d3f88c140f0/29007/apis.png 1600w,\n/static/b38495c951fb65d0bdb74d3f88c140f0/c2d13/apis.png 2560w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>To create new components we can click on create and you'll see all golden path templates ingested into the catalog as shown in screen capture below. I currently have just two.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6ae8ea059068618f507cd176d129edee/c2d13/templates.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABs0lEQVR42m2Qy27TQBhG/VBIbBqgquANQAWVbrhIoG4bUbW0UpFA6hq2fYAuoEtWSGxgC7Q4ECdxLnYutusk+Jo49uEfR0ICOtLRN/+MdOazNavTo2/aNOuCIfzoYnxr0NI79GTuNvp0jD5WY4BtjrAE23Sw2h52x2Nk+TjWBa4wbA/R1q5c5fP6Pc4fPER/8pSfjx5T27hP7fYd6ut3aci+ublJd2sLe3ubQbXKcGcH9/AF7stXtPcPae8eMKo+I9p/jlapXKf+5SvDVoux3WcyGgkOkecROpIXPtF4TDydEqscT8o5nU7whi4fPum8/3jGd71N7I/RVtdu0bEswijiV7ag+/Ydxt4e3vExwckJ1us39I6O8CSD01PSJCHNMtL5nJlkUeQU5GT5ojzTVq6tUjcMXGnjSCun0cQ9O2dimiSDAa6uCzXiXo+565Km6V8k8kAsqFRzKbSkoRoiaRkmKYuCcuVCPJuRSJMsz8mL4j/hv2grlRv4vs9c6sZxTCKofSaSROTqExdKOM+kScpMHlBcJlPn8g9vlsKlYFlbicMw/EMQBGVG0XJW95fJgjDkN0lvONQfEOenAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"templates\"\n        title=\"\"\n        src=\"/static/6ae8ea059068618f507cd176d129edee/5a190/templates.png\"\n        srcset=\"/static/6ae8ea059068618f507cd176d129edee/772e8/templates.png 200w,\n/static/6ae8ea059068618f507cd176d129edee/e17e5/templates.png 400w,\n/static/6ae8ea059068618f507cd176d129edee/5a190/templates.png 800w,\n/static/6ae8ea059068618f507cd176d129edee/c1b63/templates.png 1200w,\n/static/6ae8ea059068618f507cd176d129edee/29007/templates.png 1600w,\n/static/6ae8ea059068618f507cd176d129edee/c2d13/templates.png 2560w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Hope this was helpful. As always feel free to reach out to me if you have questions about this post or want to learn more about RedHat developer hub. I'm so excited about RedHat developer hub and backstage and the value it can add to development teams also what RedHat is doing in this space.</p>\n<p>Thanks,\nRam</p>","id":"cb7c86c4-bde9-59d7-b4ff-acc106a6001c","frontmatter":{"title":"Installing RedHat Developer Hub on Amazon Elastic Kubernetes Service (EKS)","date":"March 16, 2024","tags":["backstage","idp","kubernetes","eks","amazon","redhat"],"author":"Ram Gopinathan"},"fields":{"slug":"/installing-rhdh-on-eks/"}}},{"node":{"excerpt":"I thought I'll do this post to document some of the things I ran into when working with RedHat Developer Hub. I'm planning to keep this post updated as I learn more from my own research as well as…","html":"<p>I thought I'll do this post to document some of the things I ran into when working with RedHat Developer Hub. I'm planning to keep this post updated as I learn more from my own research as well as from customer implementations. My hope is that others will find this useful.</p>\n<p><strong>First</strong> thing I want to cover here is when you uninstall RedHat Developer Hub using helm uninstall both the PV and PVC used by Postgresql chart will still be on the cluster, because of this when you attempt to re-install the developer hub using Helm chart you will find that the Postgresql pod will not come up. Init container that configures volume permissions will fail. You are going to see this error <strong><code class=\"language-text\">chmod: changing permissions of '/var/lib/pgsql/data/userdata': Operation not permitted</code></strong> when you look at the logs for Postgresql pod. If you ran into this issue you can just simply delete the pvc first by running this command <em><code class=\"language-text\">kubectl delete pvc data-developer-hub-postgresql-0 -n tools</code></em> also make sure the associated pv is also deleted by running <em><code class=\"language-text\">kubectl get pv</code></em> and then re-install developer hub. Unfortunately we do not have much control over this as we embed the bitnami postgresql chart into the helm chart for installing developer hub</p>\n<p><strong>Second</strong> When you configure Redhat Developer Hub instance to use OKTA auth after successfully logging in you will see an error <strong><code class=\"language-text\">User not found</code></strong> this is mainly because the backstage will check to ensure a matching user entity exists in the catalog using signin resolvers. Many auth provider plugins automatically will create user entities in the catalog unfortunately Okta and Bitbucket plugins do not do this yet. One of my coworkers wrote this <a href=\"https://github.com/redhat-na-ssa/rhdh-bitbucket-auth/blob/main/Readme.Md\">post</a> that might be helpful if you are working with bitbucket or okta plugins for auth, although the article is for bitbucket, it should also work for okta.</p>\n<p><strong>Third</strong> Backstage can automatically build and publish your technical documentation and best practice is to build publish externally in a CICD pipeline. See an example of this <a href=\"https://github.com/rprakashg-redhat/petstore-go/blob/main/.github/workflows/techdocs.yaml\">here</a> backstage can serve static HTML files directly as you can see from the screen capture below</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3ccda603cfa22e0df4d92aa81571f9c7/c2d13/techdocs.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABNElEQVR42p2Py07CQBSG+1a68EYI8U1AAXHPjpCw0bABfC0TLyTS0oKUMuVSoZ3OpSx+TxtDNCFBXXw5Z85MvvmPYVpT2C8OBs9DvBHWK/VPFuz+CJ45QTB24Q7e4fTHcC0P7nAG12aYOPOM6Yig6lOdOR6MwtExHssVDGq36JeuYFI1K1VYxSKs0jXschWjmxqm9Tq8RgN+s4lFq4Wg3ca600HY7SJ66CGms7i/g3F6nsOCMSRxDLHeYLNcZqgogtyEUGEIHXEIgocRtBBIdkgkUkLHYjc38oVLuDMGoTSk1mC+DzafQyoFlSRQNDvEcrVCSAE0vc8SBsEHttstBP3AKG1K2qtU+ke+hEEmlBQ/Tlf/pywTnpxd/BBqWuE37JOlcyOXL2D1TZhecM4Psk8WcY5PgqhFMBLc6UcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"techdocs\"\n        title=\"\"\n        src=\"/static/3ccda603cfa22e0df4d92aa81571f9c7/5a190/techdocs.png\"\n        srcset=\"/static/3ccda603cfa22e0df4d92aa81571f9c7/772e8/techdocs.png 200w,\n/static/3ccda603cfa22e0df4d92aa81571f9c7/e17e5/techdocs.png 400w,\n/static/3ccda603cfa22e0df4d92aa81571f9c7/5a190/techdocs.png 800w,\n/static/3ccda603cfa22e0df4d92aa81571f9c7/c1b63/techdocs.png 1200w,\n/static/3ccda603cfa22e0df4d92aa81571f9c7/29007/techdocs.png 1600w,\n/static/3ccda603cfa22e0df4d92aa81571f9c7/c2d13/techdocs.png 2560w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>When I was first trying out the techdocs capability configuring backstage to do a build and publish locally worked fine and could see the static HTML files directly from backstage but when I switch the configuration to external docs did not render in backstage. I was getting HTTP 404 errors and the reason for this was when you publish using techdocs CLI as shown in the snippet below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">- name: Publish docs site\n  run: | \n  techdocs-cli publish --publisher-type awsS3 \\\n      --storage-name $TECHDOCS_S3_BUCKET_NAME \\\n      --entity $NAMESPACE/$KIND/$REPO_NAME</code></pre></div>\n<p>I was using k8s namespace as $NAMESPACE value. S3 router expects this to be <strong><code class=\"language-text\">default</code></strong> and also Kind should be Component matching the entity in catalog. After I fixed the pipeline I'm now able to view the static HTML files built in a CICD pipeline from backstage as you can see from the screen capture above.</p>\n<p>Hope this helps,\nRam</p>","id":"3f820f87-5a6f-5410-b55e-38c4dd0018bf","frontmatter":{"title":"Things you should know about RedHat Developer Hub","date":"March 16, 2024","tags":["backstage","idp","kubernetes","redhat"],"author":"Ram Gopinathan"},"fields":{"slug":"/rhdh-things-to-know/"}}}]}},"pageContext":{"limit":3,"skip":6,"numPages":14,"currentPage":3}},"staticQueryHashes":["1611934721","2366241629"],"slicesMap":{}}