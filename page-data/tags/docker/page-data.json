{"componentChunkName":"component---src-templates-tag-js","path":"/tags/docker/","result":{"data":{"site":{"siteMetadata":{"title":"rprakashg.github.io","author":"RAM GOPINATHAN"}},"allMarkdownRemark":{"totalCount":6,"edges":[{"node":{"excerpt":"Hugo is a great OSS project that can be used to create static sites that are based on markdown files stored in a git repository. My personal blog is created using hugo and hosted on AWS S3. I recently…","html":"<p>Hugo is a great OSS project that can be used to create static sites that are based on markdown files stored in a git repository. My personal blog is created using hugo and hosted on AWS S3. I recently did some work to dockerize it and thought I'd write about it.</p>\n<p>First thing I needed to do was create a docker image with hugo installed so I can build my hugo site. For more info on the docker image see the Dockerfile contents below, you can also check out the git repository <a href=\"https://github.com/rprakashg/hugo-docker\">here</a>. As you can see from the below snippet, nothing major is going on here, I'm using golang alpine image as a base and then installing hugo and adding hugo to the system path.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">FROM golang:1.8.3-alpine\n\nENV HUGO_VERSION 0.25 \nENV HUGO_BINARY hugo_${HUGO_VERSION}_linux-64bit \nENV PATH=/usr/local/hugo:${PATH}\n\nRUN set -x \\\n    &amp;&amp; apk upgrade --update \\\n    &amp;&amp; apk add --update ca-certificates bash curl wget \\\n    &amp;&amp; rm -rf /var/cache/apk/* \\\n    &amp;&amp; mkdir /usr/local/hugo \\\n    &amp;&amp; wget https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/${HUGO_BINARY}.tar.gz -O /usr/local/hugo/${HUGO_BINARY}.tar.gz \\\n    &amp;&amp; tar xzf /usr/local/hugo/${HUGO_BINARY}.tar.gz -C /usr/local/hugo/ \\\n  &amp;&amp; rm /usr/local/hugo/${HUGO_BINARY}.tar.gz \\\n    &amp;&amp; rm -rf /tmp/* /var/cache/apk/* </code></pre></div>\n<p>In my Dockerfile for my personal hugo based blog I use multi stage builds feature in docker to generate static HTML using hugo. As you can see from below snipped that I'm using the \"hugo-docker\" image I created as builder image and create a directory named \"blog\" under /var/www/ and copy all files into that directory.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">FROM rprakashg/hugo-docker as builder\n\nRUN mkdir -p /var/www/blog\n\nCOPY . /var/www/blog</code></pre></div>\n<p>Next, we switch the working directory to \"/var/www/blog\" and run hugo command as shown in below snippet to generate the static HTML</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">WORKDIR /var/www/blog\n\nRUN hugo</code></pre></div>\n<p>Final image is built using the official nginx image from docker hub and we copy all generated HTML content from \"public\" folder into \"/usr/share/nginx/html\"</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">FROM nginx\n\nCOPY --from=builder /var/www/blog/public/ /usr/share/nginx/html</code></pre></div>\n<p>You can see the full docker file <a href=\"https://raw.githubusercontent.com/rprakashg/blog/master/Dockerfile\">here</a></p>\n<p>Lastly, I threw together couple of helpful bash scripts that I can use to build and run the container so I don't have to always remember the docker commands :)</p>\n<p>The cool thing about this is I can now run my blog anywhere, I use to host my blog previously in azure with Wordpress and MySQL, by using hugo I freed myself from dependency to web servers, runtimes, databases etc. but was still dependant on AWS S3 to host the generated static HTML content. Even though its pretty minor you are sort of locked into AWS. Docker gives me freedom to run it anywhere and I love it :)</p>\n<p>Hope that helps...</p>\n<p>Cheers,</p>\n<p>Ram</p>","id":"70884df6-d575-52ab-bf71-a41cf8137683","frontmatter":{"title":"Dockerizing Hugo Sites","date":"November, 2017","tags":["hugo","docker","blog"]},"fields":{"slug":"/dockerizing-hugo-sites/"}}},{"node":{"excerpt":"It's extremely important to always be aware of all the announcements related to security issues for the products you use and support within your company, If you use slack we can have all these…","html":"<p>It's extremely important to always be aware of all the announcements related to security issues for the products you use and support within your company, If you use <a href=\"https://slack.com/\">slack</a> we can have all these announcements posted directly to a slack channel. In this post, I will go over how we can do just that for Docker.</p>\n<h1>Approach</h1>\n<p>You can get a list of known security vulnerabilities using <a href=\"http://www.cvedetails.com\">www.cvedetails.com</a> website. Known security vulnerabilities can be searched by the vendor, product, version etc.\nBelow RSS feed will provide you all known security vulnerabilities for Docker\n<a href=\"http://www.cvedetails.com/vulnerability-feed.php?vendor_id=13534&#x26;orderby=3&#x26;cvssscoremin=0\">http://www.cvedetails.com/vulnerability-feed.php?vendor_id=13534&#x26;orderby=3&#x26;cvssscoremin=0</a></p>\n<p>If you want to further filter down by specific product or version you can simply add \"product_id\" and/or \"version_id\" to the query string. To find the product id or version id <a href=\"http://www.cvedetails.com\">www.cvedetails.com</a> site provides product search and version search capabilities, once you have found the product through the search capability you can simply copy the product id and/or version id from the address bar in your browser and include it in the query string for above RSS feed URL</p>\n<p>From the above RSS feed URL vendor id \"13534\" is for Docker.</p>\n<p>Create a slack channel named \"docker\" in your slack workspace where we can post all security vulnerabilities related to Docker as well as have all docker related discussions.</p>\n<p>Copy the above RSS URL and issue following command in the slack channel.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">/feed subscribe http://www.cvedetails.com/vulnerability-feed.php?vendor_id<span class=\"token operator\">=</span><span class=\"token number\">13534</span><span class=\"token operator\">&amp;</span><span class=\"token assign-left variable\">orderby</span><span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token operator\">&amp;</span><span class=\"token assign-left variable\">cvssscoremin</span><span class=\"token operator\">=</span><span class=\"token number\">0</span></code></pre></div>\n<p>Before you subscribe to RSS feed verify that it's not already subscribed by issuing command below which will list out all the RSS feeds that are already subscribed</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">/feed list</code></pre></div>\n<p>Once you receive an announcement you should evaluate it and if you are affected by it patch or mitigate the risk, test it and notify everyone.</p>\n<p>Hope this helps...</p>\n<p>Cheers,\nRam</p>","id":"2fa0ad21-16a7-5e7f-9322-bf288514155a","frontmatter":{"title":"Automatically get latest Docker security vulnerabilities posted to slack channel","date":"October, 2017","tags":["docker","cve","security","slack"]},"fields":{"slug":"/post-docker-security-updates-to-slack/"}}},{"node":{"excerpt":"What is Configuration as code? Configuration as code is a DevOps practice that promotes storing of application configuration as code within source code repository. Few key benefits that this brings is…","html":"<h2>What is Configuration as code?</h2>\n<p>Configuration as code is a DevOps practice that promotes storing of application configuration as code within source code repository. Few key benefits that this brings is that</p>\n<ul>\n<li>\n<p>Versioning of application configuration</p>\n<p>By storing the application configuration in source code repository such as Git allows us to see what configuration changes were made over a period of time and who made those changes</p>\n<p>By using branches you can isolate changes that are under development without affecting the production application</p>\n</li>\n<li>\n<p>Traceability</p>\n<p>Versioned and managed properly, can provide tracking of what version of configuration is deployed in various environments</p>\n</li>\n<li>\n<p>Make configuration changes without requiring to re-deploy application</p>\n<p>Operators would love you for this for ex. Operators can throttle logging level up in configuration settings file to troubleshoot a production issue without having to redeploy the application.</p>\n</li>\n</ul>\n<h2>Implementation</h2>\n<p>Now that we understand what configuration as code is and what benefits it brings let's take a look at how we would implement this with docker and spring boot. Spring boot provides support for keeping configuration settings in \"yml\" files instead of using a properties files, by default spring boot looks for these \"yml\" files under classpath but you can specify an explicit location by setting \"spring.config.location\" property via command line during application startup.</p>\n<p>For the purpose of this article we have stored all default configurations for this demo application application.yml file and environment specific settings are stored in application-{environment label}.yml file as shown in screen capture below</p>\n<p><img src=\"/images/dzone4.png?raw=true\" alt=\"\"></p>\n<p>Since we are running the spring boot app in docker, we can use an \"entrypoint.sh\" bash script to pull default configuration and environment specific configuration files from \"git\" repository onto directory named \"configs\" as shown below using wget command.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"Downloading configuration files from git repository\"</span>\n<span class=\"token function\">wget</span>  <span class=\"token variable\">$GIT_REPO</span>/<span class=\"token variable\">$LABEL</span>/<span class=\"token variable\">$REL_PATH</span>/<span class=\"token variable\">$APP_NAME</span>.yml\n<span class=\"token function\">wget</span>  <span class=\"token variable\">$GIT_REPO</span>/<span class=\"token variable\">$LABEL</span>/<span class=\"token variable\">$REL_PATH</span>/<span class=\"token variable\">$APP_NAME</span>-<span class=\"token variable\">$PROFILE</span>.yml\n\n<span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"copying yml files to configs directory\"</span>\n<span class=\"token function\">cp</span> <span class=\"token variable\">$APP_NAME</span>.yml ./configs/<span class=\"token variable\">$APP_NAME</span>.yml\n<span class=\"token function\">cp</span> <span class=\"token variable\">$APP_NAME</span>-<span class=\"token variable\">$PROFILE</span>.yml ./configs/<span class=\"token variable\">$APP_NAME</span>-<span class=\"token variable\">$PROFILE</span>.yml</code></pre></div>\n<p>As you can see from the above snippet</p>\n<ul>\n<li>\n<p>\"GIT_REPO\" environment variable is used to pass the git repository URL where the configuration files are stored.</p>\n</li>\n<li>\n<p>\"LABEL\" environment variable maps to the branch, in development/test/staging phases you might use \"MASTER\", when you release it to production you'll want to create a branch and use that branch label. This allows us to isolate changes that are under development from impacting the production application.</p>\n</li>\n<li>\n<p>\"REL_PATH\" environment variable is used to point to the location of configuration files in repo relative to the repository path.</p>\n</li>\n<li>\n<p>\"APP_NAME\" environment variable maps to file name, in the demo app I'm keeping default name \"application\"</p>\n</li>\n<li>\n<p>\"PROFILE\" environment variable maps to name of environment which the application is running. Spring boot will merge the default settings and environment specific settings and provide it to your application.</p>\n</li>\n</ul>\n<p>(Note: If your git repository requires authentication you can use ssh or HTTPS protocol with username and password to authenticate with the git repository. Docker container can obtain the credentials required to connect to git repository during startup.)</p>\n<p>Once the configuration files are downloaded from repository onto \"configs\" directory in the container we specify this location via application startup using the \"spring.config.location\" property as shown in below snippet</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">exec</span> java <span class=\"token variable\">$JAVA_OPTS</span> -jar /app.jar --spring.config.location<span class=\"token operator\">=</span><span class=\"token string\">\"./configs/<span class=\"token variable\">$APP_NAME</span>.yml, ./configs/<span class=\"token variable\">$APP_NAME</span>-<span class=\"token variable\">$PROFILE</span>.yml\"</span></code></pre></div>\n<h2>Running the demo application</h2>\n<p>Let's now run this demo application with staging settings as shown in command below</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">docker run -d -p <span class=\"token number\">80</span>:8080 -e <span class=\"token assign-left variable\">PROFILE</span><span class=\"token operator\">=</span>staging -e <span class=\"token assign-left variable\">GIT_REPO</span><span class=\"token operator\">=</span><span class=\"token string\">\"https://raw.githubusercontent.com/rprakashg/blog-demos\"</span> <span class=\"token punctuation\">\\</span>\n    -e <span class=\"token assign-left variable\">LABEL</span><span class=\"token operator\">=</span>master -e <span class=\"token assign-left variable\">REL_PATH</span><span class=\"token operator\">=</span><span class=\"token string\">\"externalize-config-demo/src/main/resources\"</span> <span class=\"token punctuation\">\\</span>\n    -e <span class=\"token assign-left variable\">APP_NAME</span><span class=\"token operator\">=</span><span class=\"token string\">\"application\"</span> rprakashg/externalize-config-demo</code></pre></div>\n<p>Demo application simply displays the configuration information and you can see from the screen capture below that application has picked up default settings as well as staging environment specific settings.\n<img src=\"/images/dzone5.png?raw=true\" alt=\"\"></p>\n<p>Let's run the same demo application now with production settings as shown in snippet below.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">docker run -d -p <span class=\"token number\">80</span>:8080 -e <span class=\"token assign-left variable\">PROFILE</span><span class=\"token operator\">=</span>production -e <span class=\"token assign-left variable\">GIT_REPO</span><span class=\"token operator\">=</span><span class=\"token string\">\"https://raw.githubusercontent.com/rprakashg/blog-demos\"</span> <span class=\"token punctuation\">\\</span>\n    -e <span class=\"token assign-left variable\">LABEL</span><span class=\"token operator\">=</span>master -e <span class=\"token assign-left variable\">REL_PATH</span><span class=\"token operator\">=</span><span class=\"token string\">\"externalize-config-demo/src/main/resources\"</span> <span class=\"token punctuation\">\\</span>\n    -e <span class=\"token assign-left variable\">APP_NAME</span><span class=\"token operator\">=</span><span class=\"token string\">\"application\"</span> rprakashg/externalize-config-demo</code></pre></div>\n<p>As you can see from the screen show below that the application now picks up default as well as production specific settings.</p>\n<p><img src=\"/images/dzone6.png?raw=true\" alt=\"\"></p>\n<h2>Source Code</h2>\n<p>All the code for the demo application is available at this github <a href=\"https://github.com/rprakashg/blog-demos/tree/master/externalize-config-demo\">repository</a></p>\n<h2>Conclusion</h2>\n<p>Configuration as code is a good practice that all development teams practicing devops should follow. Many of the benefits gained from implementing configuration as code can help increase velocity and deliver new features to your customers in production faster and help operators run and manage application in production efficiently.</p>","id":"c6b39486-e322-5d0a-9c38-78e56755a83c","frontmatter":{"title":"Configuration As Code With Docker and Spring Boot","date":"September, 2017","tags":["java","devops","microservices","docker"]},"fields":{"slug":"/config-as-code-with-docker-spring-boot/"}}},{"node":{"excerpt":"Why? In Many enterprises leveraging Jenkins for running automated builds, it's quite common to have a central team providing Jenkins and other CI/CD tools as shared service. One of the issues that you…","html":"<h1>Why?</h1>\n<p>In Many enterprises leveraging Jenkins for running automated builds, it's quite common to have a central team providing Jenkins and other CI/CD tools as shared service. One of the issues that you quickly run into is that each development group within enterprise may have different platforms, frameworks, tools, libraries etc and to support the needs of everyone you end up provisioning jenkins build slaves for each group installing everything a particular group needs to be able to build/run jenkins jobs on these Jenkins slave nodes. Depending on number of groups you are supporting, this can get pretty difficult to manage. Thankfully for docker and the Jenkins community there is a docker plugin for Jenkins that can be used to dynamically provision a build slave as a docker container running on a remote docker host, run the build job and tear it down at the end of it. There a numerous benefits with this approach.</p>\n<ol>\n<li>Each development group can build the slave docker image according to their specification and through a CI process build/push the image to a docker registry keeping full ownership within the development team itself. No need to file any requests to get the tools you need installed on jenkins build slaves before your can create your CI/CD processes</li>\n<li>From an Operator's perspective you now have less number of build slaves to manage, preferably zero. I know our teams goal is to get to zero build slaves with fully dockerized approach.</li>\n</ol>\n<p>Here are the steps you can perform to leverage docker for dynamically provisioning a build slave as container:</p>\n<ul>\n<li>Install Docker Plugin</li>\n<li>Enable Docker Remote API on docker host</li>\n<li>Create a Docker image for Jenkins build slave</li>\n<li>Configure Jenkins</li>\n<li>Creating Jenkins job to run on docker</li>\n</ul>\n<h2>Install Docker Plugin</h2>\n<p>For the purposes of this post I installed a single node Jenkins server using Vagrant, I won't go too much into how I setup Jenkins as its all well documented and pretty easy to get setup. To install the docker plugin, login to Jenkins console and click on manage jenkins and from manage jenkins click on manage plugins. Switch to the available tab and you can scroll down or use the filter to find the docker plugin, select it to install. You may need to restart jenkins server for changes to get in effect.</p>\n<h2>Enable Docker Remote API on docker host</h2>\n<p>This is important step, plugin communicates with Docker via remote rest API which is turned off by default. You can enable it by simply adding below options to your dockerd startup</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock</code></pre></div>\n<p>For the purposes of this demo I installed docker on centos/7 using Vagrant, if you installed docker on centos/7 you can update /usr/lib/systemd/system/docker.service file, look for ExecStart=/usr/bin/dockerd and add above options to dockerd. Restart docker by running commands below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sudo systemctl daemon-reload\nsudo systemctl restart docker</code></pre></div>\n<h2>Create a Docker image for Jenkins build slave</h2>\n<p>First thing to keep in mind here is depending on the platform that you are using to build your application, choose an appropriate base image, there are lots of base images available for Java, Golang, Node etc. If none fits the bill start from scratch and add everything you need to it. Docker image should also have following:</p>\n<ol>\n<li>SSH server installed</li>\n<li>OpenJDK</li>\n<li>User that you can use to login with, typically \"jenkins\"</li>\n</ol>\n<p>Docker image should also expose port 22 for SSH and start sshd service when container is run. See an example Dockerfile that I use to create a jenkins slave image for running Hugo builds</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">FROM golang:1.8.3-alpine\n\nMAINTAINER Ramprakash.Gopinathan@t-mobile.com\n\nENV HUGO_VERSION 0.25\nENV HUGO_BINARY hugo_${HUGO_VERSION}_linux-64bit\nENV PATH=/usr/local/hugo:${PATH}\n\nRUN set -x \\\n    &amp;&amp; apk --no-cache update \\\n    &amp;&amp; apk --no-cache upgrade \\\n    &amp;&amp; apk --no-cache add git bash curl openssh python python-dev py-pip py-pygments openjdk8 wget\\\n    &amp;&amp; ssh-keygen -A \\\n    &amp;&amp; rm -rf /var/cache/apk/* \\\n    &amp;&amp; adduser -D jenkins \\\n    &amp;&amp; echo \"jenkins:jenkins\" | chpasswd \\\n    &amp;&amp; mkdir -p /var/run/sshd \\\n    &amp;&amp; mkdir /usr/local/hugo \\\n    &amp;&amp; wget https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/${HUGO_BINARY}.tar.gz -O /usr/local/hugo/${HUGO_BINARY}.tar.gz \\\n    &amp;&amp; tar xzf /usr/local/hugo/${HUGO_BINARY}.tar.gz -C /usr/local/hugo/ \\\n\t&amp;&amp; rm /usr/local/hugo/${HUGO_BINARY}.tar.gz \\\n    &amp;&amp; pip install --upgrade pip \\\n    &amp;&amp; pip install awscli \\\n    &amp;&amp; git clone https://github.com/s3tools/s3cmd.git /opt/s3cmd \\\n    &amp;&amp; ln -s /opt/s3cmd/s3cmd /usr/bin/s3cmd \n\nEXPOSE 22\n\nCMD [\"/usr/sbin/sshd\", \"-D\"]</code></pre></div>\n<p>Build the docker image and publish to your internal private docker registry, this allows you to login to your private registry from Docker host and pull the image down. You could always run docker save command to create a tar ball and scp this to docker host and run docker load to get the image on to the docker host.</p>\n<h2>Configure Jenkins</h2>\n<p>We now need configure Jenkins to use Docker for dynamically provisioning slave as containers on docker host. Login to your Jenkins console and click on \"Manage Jenkins\" option. From manage jenkins click on \"Configure System\" option and scroll all the way to the bottom of the page.\nUnder \"Cloud\" section click on \"Add a new cloud\" button. If the plugin is installed correctly you will see \"Docker\" option as shown below.</p>\n<p><img src=\"/images/jenkins3.jpg?raw=true\" alt=\"\"></p>\n<p>Enter information about your docker host. As I mentioned earlier I setup a docker host using vagrant for the purposes of this demo and created an entry in my /etc/hosts file to map the IP address of the VM to docker.local. You can test to make sure Jenkins server is able to talk to docker host by clicking on \"Test Connection\" button. See screenshot below:</p>\n<p><img src=\"/images/jenkins4.jpg?raw=true\" alt=\"\"></p>\n<p>Next enter image information such as full image name, Labels and credential to connect to the slave, this will be the user we created in docker file for the slave image. Labels allow us to restrict the builds. See screenshot below. I've added the java image \"evarga/jenkins-slave\" and the one I've created for running hugo builds, see more on that <a href=\"https://goo.gl/5ecm2V\">here</a></p>\n<p><img src=\"/images/jenkins5.jpg?raw=true\" alt=\"\"></p>\n<h2>Creating jenkins job to run on docker</h2>\n<p>At this point you are ready to run your build jobs on docker. Simply configure your job and specify Label Expression use docker as shown below.</p>\n<p><img src=\"/images/jenkins6.jpg?raw=true\" alt=\"\"></p>\n<p>Hope this helps, As usual any comments or questions please use the disqus option below</p>\n<p>Cheers,\nRam</p>","id":"c6a957a8-8548-50c4-991b-ca2486819827","frontmatter":{"title":"Using docker for dynamically provisioning jenkins build slaves and running build jobs","date":"July, 2017","tags":["jenkins","docker"]},"fields":{"slug":"/jenkins-build-slave-as-container/"}}},{"node":{"excerpt":"Overview At T-Mobile we are starting to leverage Hugo which is an OSS static site generator tool for a few marketing type of sites. We are also huge Jenkins shop and run jenkins build slaves in docker…","html":"<h1>Overview</h1>\n<p>At T-Mobile we are starting to leverage <a href=\"http://gohugo.io\">Hugo</a> which is an OSS static site generator tool for a few marketing type of sites. We are also huge Jenkins shop and run jenkins build slaves in docker and Mesos/Marathon. We use S3 bucket for hosting content generated, cloudfront for global content delivery and route 53 for DNS. I've created a docker jenkins build slave image for building hugo projects in Jenkins. Image comes preloaded with Hugo and AWS CLI along with S3Cmd utility that is typically used for syncing content to S3 bucket.</p>\n<p>If you are using Hugo and Jenkins you'll find this image useful. Image is available in docker hub. You can run command below to pull the image down to your docker host that your are using with Jenkins. If you have any issues and or comments or questions let me know.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker pull rprakashg/hugo-jenkins-build-slave</code></pre></div>\n<p>Git repository for this image is <a href=\"http://github.com/rprakashg/hugo-jenkins-build-slave\">here</a></p>\n<p>Cheers,</p>\n<p>Ram</p>","id":"e90a1166-b4c4-5650-ae84-1aef654cee74","frontmatter":{"title":"Jenkins Build Slave Image For Building Hugo Projects","date":"July, 2017","tags":["jenkins","docker","hugo"]},"fields":{"slug":"/hugo-jenkins-build-slave-image/"}}},{"node":{"excerpt":"At T-Mobile we use jFrog artifactory as a centralized repository for storing artifacts. It is one of the key tools in our DevOps toolset and is integrated into our CI/CD processes. Artifactory has…","html":"<p>At T-Mobile we use jFrog <a href=\"https://www.jfrog.com/artifactory/\">artifactory</a> as a centralized repository for storing artifacts. It is one of the key tools in our DevOps toolset and is integrated into our CI/CD processes. Artifactory has support for storing docker images in repositories, essentially its like running private docker registries.\nArtifactory lets you create multiple docker repositories which is pretty nice for a large company like T-Mobile where there are numerous groups developing dockerized microservices, each group can have thier own repository (registry in docker terminology) with right level of access control that governs who can push images into it.</p>\n<p>If you are using Artifactory for hosting private Docker registries in enterprise, below are few things to keep in mind. Later I will cover how we have addressed these.</p>\n<ul>\n<li>\n<p>Discovering images that are stored in multiple repositories</p>\n<p>With flexibility of running multiple docker registries, discovering images becomes bit of a challenge, artifactory web portal has some nice search functionality built in which helps, but if you are in docker cli you have to know the name of the repository before you can search or pull the image down</p>\n</li>\n<li>\n<p>Governing Use of Docker Images from Docker Hub</p>\n<p>Docker hub is public registry where thousands of open source developers and ISVs are publishing docker images for thier products. In the enterprise it becomes critical to ensure the use of appropriate images for production deployment. You don't want a group by mistake use an image that has security vulnerabilities or is not certified by docker to run well on docker platforms. The new docker store addresses some of these challenges enterprises face but governing use of docker images for production still is a critical things every enterprise needs to ensure.</p>\n</li>\n<li>\n<p>Promoting docker images to release registry</p>\n<p>One of the policies we have is any docker image deployed to our production Mesos stack has to come from release repository in artifactory. Only the service account used by Jenkins job has rights to push to release registry. For those who might be new to Artifactory, when you create docker repository in Artifactory, artifactory creates \"<em>-snapshot-local\" and \"</em>-release-local\" repositories. Snapshot is where images that are still in development stored, before a docker image is deployed to production they get promoted to release repository. Another benefit with this model is that you can have seperate retention policies for images stored in these repos, for ex. We have a default 15 day retention policy for anything in Snapshot, you can request to increase this. Obviously images in release repo has unlimited retention</p>\n</li>\n</ul>\n<h2>How did we address the above three things</h2>\n<p>For the first bullet point, we use a virtual docker repository that aggregates images from all docker repositories in artifactory. Few benefits of doing this is that</p>\n<ol>\n<li>\n<p>It Provides a single endpoint for developers to resolve images from docker registries in artifactory. This is huge in the enterprise, think about in the past if you needed to reuse something another group had built, I can tell you it almost never happens, there are many reasons for this which I wont get in to but in summary lots of duplication of effort is what ends up happening. Containerization movement within our company and use of Docker and Artifactory is really changing how teams work, there is less duplication, developers can build/push images into docker registries in artifactory and other developers inside and outside of their respective groups can discover and use these images avoiding duplication of efforts etc.</p>\n</li>\n<li>\n<p>The other key benefit is IT operators can manage these docker registries such as moving/consolidating images or modify include and exclude patterns to enfore security policies without worrying about impacting developers.</p>\n</li>\n</ol>\n<p>For the second bullet point we are using remote repository which is seeded with approved images for production use from docker hub. Virtual repository also aggregates images from remote repository freeing developers to ever needing to pull any image from docker hub.</p>\n<p>For the third bullet point we use docker tagging in Jenkins job to promote images that are ready for production deployment from snapshot to release.</p>\n<p>Jenkins job first we pull the image from snapshot registry as shown below...</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker pull {artifactory host}/{docker snapshot registry}/{image name}:{tag} \n</code></pre></div>\n<p>Next we use docker tagging to include release registry as shown below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker tag {artifactory host}/{docker snapshot registry}/{image name}:{tag} {artifactory host}/{docker release registry}/{image name}:{tag}</code></pre></div>\n<p>Lastly we use docker push to promote the image to release registry</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker push artifactory host}/{docker release registry}/{image name}:{tag}</code></pre></div>\n<p>Below is a diagram that shows how we use artifactory for hosting private docker registries</p>\n<p><img src=\"http://rprakashg.io/images/artifactory.jpg\" alt=\"artifactory structure\"></p>","id":"b4c5718e-8488-5ff5-b3c9-6c39b099665c","frontmatter":{"title":"Some thoughts on running docker registries in jFrog artifactory","date":"May, 2017","tags":["docker","artifactory","registry","discovery"]},"fields":{"slug":"/docker-registries-with-artifactory/"}}}]}},"pageContext":{"tag":"docker"}},"staticQueryHashes":["1468229134","1611934721"]}